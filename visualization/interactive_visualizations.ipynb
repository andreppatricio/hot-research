{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e07b8952-22d5-44f5-88e5-6f27d168a902",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywidgets import interact\n",
    "import viz_functions\n",
    "\n",
    "import os\n",
    "\n",
    "postgres_user = os.environ.get('POSTGRES_USER')\n",
    "postgres_password = os.environ.get('POSTGRES_PASSWORD')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37f75c3c",
   "metadata": {},
   "source": [
    "## Setup Connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "af851a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"PostgreSQL Connection with PySpark\") \\\n",
    "    .config(\"spark.jars\", \"/visualization/postgresql-42.6.0.jar\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "url = \"jdbc:postgresql://postgres:5432/airflow\"\n",
    "\n",
    "properties = {\n",
    "    \"user\": \"airflow\",\n",
    "    \"password\": \"airflow\",\n",
    "    \"driver\": \"org.postgresql.Driver\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db748d7e",
   "metadata": {},
   "source": [
    "## Load Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "01c0ba02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "########## paper ##########\n",
      "root\n",
      " |-- api_name: string (nullable = true)\n",
      " |-- api_id: string (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- doi: string (nullable = true)\n",
      " |-- published_date: date (nullable = true)\n",
      " |-- publisher: string (nullable = true)\n",
      "\n",
      "+--------+---------+--------------------+-------------------+--------------+--------------------+\n",
      "|api_name|   api_id|               title|                doi|published_date|           publisher|\n",
      "+--------+---------+--------------------+-------------------+--------------+--------------------+\n",
      "|    core|137628615|Glucose Homeostas...|10.22028/d291-38686|    2023-01-06|Saarländische Uni...|\n",
      "|    core|138044939|COMPASSION FOR TH...|                NaN|    2023-01-06|The Graduate Scho...|\n",
      "+--------+---------+--------------------+-------------------+--------------+--------------------+\n",
      "only showing top 2 rows\n",
      "\n",
      "Total rows: 792650\n",
      "\n",
      "########## author ##########\n",
      "root\n",
      " |-- api_name: string (nullable = true)\n",
      " |-- api_id: string (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      "\n",
      "+--------+---------+------------------+\n",
      "|api_name|   api_id|              name|\n",
      "+--------+---------+------------------+\n",
      "|    core|137628615|Rössler, Oliver G.|\n",
      "|    core|137628615|     Thiel, Gerald|\n",
      "+--------+---------+------------------+\n",
      "only showing top 2 rows\n",
      "\n",
      "Total rows: 4212056\n",
      "\n",
      "########## journal ##########\n",
      "root\n",
      " |-- api_name: string (nullable = true)\n",
      " |-- api_id: string (nullable = true)\n",
      " |-- issn: string (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      "\n",
      "+--------+---------+----------+--------------------+\n",
      "|api_name|   api_id|      issn|                name|\n",
      "+--------+---------+----------+--------------------+\n",
      "|    core|137628615| 1422-0067|International Jou...|\n",
      "|    core|139451807| 1831-9424|                 NaN|\n",
      "+--------+---------+----------+--------------------+\n",
      "only showing top 2 rows\n",
      "\n",
      "Total rows: 226561\n",
      "\n",
      "########## keyword ##########\n",
      "root\n",
      " |-- week_start_date: date (nullable = true)\n",
      " |-- n: integer (nullable = true)\n",
      " |-- word: string (nullable = true)\n",
      " |-- count: integer (nullable = true)\n",
      " |-- week_percentage: float (nullable = true)\n",
      "\n",
      "+---------------+---+----------+-----+---------------+\n",
      "|week_start_date|  n|      word|count|week_percentage|\n",
      "+---------------+---+----------+-----+---------------+\n",
      "|     2023-01-02|  1|     based|  846|        0.58535|\n",
      "|     2023-01-02|  2|rov survey|  276|        0.32491|\n",
      "+---------------+---+----------+-----+---------------+\n",
      "only showing top 2 rows\n",
      "\n",
      "Total rows: 24000\n"
     ]
    }
   ],
   "source": [
    "schema = 'papers'\n",
    "tables = ['paper', 'author', 'journal', 'keyword']\n",
    "\n",
    "for table in tables:\n",
    "    table_name = f'{schema}.{table}'\n",
    "    df = spark.read.jdbc(url, table_name, properties=properties)\n",
    "    df.createOrReplaceTempView(table)\n",
    "    print(f\"\\n########## {table} ##########\")\n",
    "    df.printSchema()\n",
    "    df.show(2)\n",
    "    print(f\"Total rows: {df.count()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "15080a6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.date(2023, 10, 30)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dates = spark.sql(\"SELECT DISTINCT week_start_date FROM keyword ORDER BY week_start_date DESC\")\n",
    "dates = dates.rdd.map(lambda row: row[0]).collect()\n",
    "current_week = dates[0]\n",
    "current_week"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f4efa14",
   "metadata": {},
   "source": [
    "## Visualize Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "22899165",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "faf444e861464ac6ba250f16ce80fe76",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='table', options=('paper', 'author', 'journal', 'keyword'), value='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@interact\n",
    "def display_tables(table=tables, nrows=(1, 20, 1)):\n",
    "    df = spark.sql(f\"SELECT * FROM {table};\").toPandas()\n",
    "    return df.head(nrows)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c4036da",
   "metadata": {},
   "source": [
    "## Top n-grams By Date Interval "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43501437",
   "metadata": {},
   "source": [
    "### Barplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "517f5c49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29a57f7c80f04f2aa65009939a0485e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='start_date', options=(datetime.date(2023, 10, 30), datetime.date(2…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@interact\n",
    "def int_barplot_grams(start_date=dates, n=(1,3,1), limit=(5,20,1)):\n",
    "    query = \"\"\"\n",
    "                SELECT word, count\n",
    "                FROM keyword\n",
    "                WHERE week_start_date = '{week_start}'\n",
    "                AND n = {n}\n",
    "                ORDER BY count DESC\n",
    "                LIMIT {limit}\n",
    "            \"\"\".format(**{'week_start': start_date, 'n': n, 'limit': limit})\n",
    "    viz_functions.barplot_ngrams(spark, query, x='word', y='count', title=f\"This week's most used {n}-grams\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e267aafb",
   "metadata": {},
   "source": [
    "### Word Cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9931414c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa4c0a0448764905aa26acdc45c0dfdf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='start_date', options=(datetime.date(2023, 10, 30), datetime.date(2…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "colormaps = [\"gist_heat_r\", \"Reds_r\", \"Purples_r\", \"RdGy_r\", \"RdBu_r\", \"CMRmap_r\"]\n",
    "\n",
    "@interact\n",
    "def it_wordcloud_ngrams(start_date=dates, end_date=dates, n=(1,3,1), limit=(5,20,1), colormap=colormaps):\n",
    "    query = \"\"\"\n",
    "                SELECT word, count\n",
    "                FROM keyword\n",
    "                WHERE week_start_date = '{week_start}'\n",
    "                AND n = {n}\n",
    "                ORDER BY count DESC\n",
    "                LIMIT {limit}\n",
    "            \"\"\".format(**{'week_start': start_date, 'n': n, 'limit': limit})\n",
    "    viz_functions.wordcloud_ngrams(spark, query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a0dbc35",
   "metadata": {},
   "source": [
    "## Keyword Evolution Through Time "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9fe1924f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2849398eab14dd48763dcab81e83ff2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='week', options=(datetime.date(2023, 11, 6), datetime.date(2023, 10…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@interact\n",
    "def it_lineplot_ngrams(week=dates, n=(1,3,1), limit=(4,20,1)):\n",
    "    query = \"\"\"\n",
    "            SELECT kw.week_start_date, kw.word, kw.week_percentage\n",
    "            FROM keyword as kw \n",
    "            INNER JOIN\n",
    "            (\n",
    "                SELECT word, count\n",
    "                FROM keyword\n",
    "                WHERE week_start_date = '{week_start}'\n",
    "                AND n = {n}\n",
    "                ORDER BY count DESC\n",
    "                LIMIT {limit} ) as temp \n",
    "            ON kw.word = temp.word;\n",
    "        \"\"\".format(**{'week_start': week, 'n': n, 'limit': limit})\n",
    "\n",
    "    viz_functions.lineplot_ngrams(spark, query, x=\"week_start_date\", y=\"week_percentage\", hue=\"word\", title=f\"Evolution of this week's top {n}-grams\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96b3f367",
   "metadata": {},
   "source": [
    "## Publications per Journal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "36e887ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0aef53bc269343fc96ce466f06b9ac05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='year', options=(2023,), value=2023), IntSlider(value=6, descriptio…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "years = spark.sql(\n",
    "    \"\"\"\n",
    "    SELECT DISTINCT EXTRACT(YEAR FROM published_date) as year\n",
    "    FROM paper \n",
    "    ORDER BY year DESC\n",
    "    \"\"\")\n",
    "years = years.rdd.map(lambda row: row[0]).collect()\n",
    "\n",
    "@interact\n",
    "def it_barplot_journals(year=years, month=(1,12,1), limit=(5,20,1)):\n",
    "    query = \"\"\"\n",
    "                SELECT j.name as Name, j.issn as ISSN, COUNT(*) as count\n",
    "                FROM journal as j\n",
    "                INNER JOIN (\n",
    "                    SELECT api_name, api_id\n",
    "                    FROM paper\n",
    "                    WHERE EXTRACT(MONTH FROM published_date) = {month}\n",
    "                    AND EXTRACT(YEAR FROM published_date) = {year}\n",
    "                ) as p\n",
    "                ON (j.api_name, j.api_id) = (p.api_name, p.api_id)\n",
    "                WHERE j.name IS NOT NULL\n",
    "                AND j.name != 'NaN'\n",
    "                GROUP BY j.name, j.issn\n",
    "                ORDER BY count DESC\n",
    "                LIMIT {limit};\n",
    "            \"\"\".format(**{'month': month, 'year': year, 'limit': limit})\n",
    "    viz_functions.barplot_journals(spark, query, x='Name', y='count')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "428a80aa",
   "metadata": {},
   "source": [
    "## Publications per Author"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45a04597",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b05f42d090f64474a5c0389f82e1c13d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='year', options=(2023,), value=2023), IntSlider(value=6, descriptio…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@interact\n",
    "def barplot_ngrams(year=years, month=(1,12,1), limit=(5,20,1)):\n",
    "    query = \"\"\"\n",
    "                SELECT a.name as Name, COUNT(*) as count\n",
    "                FROM author as a\n",
    "                INNER JOIN (\n",
    "                    SELECT api_name, api_id\n",
    "                    FROM paper\n",
    "                    WHERE EXTRACT(MONTH FROM published_date) = {month}\n",
    "                    AND EXTRACT(YEAR FROM published_date) = {year}\n",
    "                ) as p\n",
    "                ON (a.api_name, a.api_id) = (p.api_name, p.api_id)\n",
    "                WHERE a.name IS NOT NULL\n",
    "                AND a.name != 'NaN'\n",
    "                GROUP BY a.name\n",
    "                ORDER BY count DESC\n",
    "                LIMIT {limit};\n",
    "            \"\"\".format(**{'month': month, 'year': year, 'limit': limit})\n",
    "    viz_functions.barplot_authors(spark, query, x='Name', y='count')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
