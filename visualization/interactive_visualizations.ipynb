{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e07b8952-22d5-44f5-88e5-6f27d168a902",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact, interact_manual\n",
    "import viz_functions\n",
    "\n",
    "import os\n",
    "\n",
    "postgres_user = os.environ.get('POSTGRES_USER')\n",
    "postgres_password = os.environ.get('POSTGRES_PASSWORD')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37f75c3c",
   "metadata": {},
   "source": [
    "## Setup Connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "af851a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"PostgreSQL Connection with PySpark\") \\\n",
    "    .config(\"spark.jars\", \"/visualization/postgresql-42.6.0.jar\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "url = \"jdbc:postgresql://postgres:5432/paper_db\"\n",
    "\n",
    "properties = {\n",
    "    \"user\": \"airflow\",\n",
    "    \"password\": \"airflow\",\n",
    "    \"driver\": \"org.postgresql.Driver\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db748d7e",
   "metadata": {},
   "source": [
    "## Load Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "01c0ba02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "########## paper ##########\n",
      "root\n",
      " |-- api_name: string (nullable = true)\n",
      " |-- api_id: string (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- doi: string (nullable = true)\n",
      " |-- published_date: date (nullable = true)\n",
      " |-- publisher: string (nullable = true)\n",
      "\n",
      "+--------+---------+--------------------+---+--------------+---------+\n",
      "|api_name|   api_id|               title|doi|published_date|publisher|\n",
      "+--------+---------+--------------------+---+--------------+---------+\n",
      "|    core|147867716|Blockchain-enable...|NaN|    2023-09-08|      NaN|\n",
      "|    core|147867886|Multifunction ful...|NaN|    2023-09-08|      NaN|\n",
      "+--------+---------+--------------------+---+--------------+---------+\n",
      "only showing top 2 rows\n",
      "\n",
      "Total rows: 95446\n",
      "\n",
      "########## author ##########\n",
      "root\n",
      " |-- api_name: string (nullable = true)\n",
      " |-- api_id: string (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      "\n",
      "+--------+---------+----------------+\n",
      "|api_name|   api_id|            name|\n",
      "+--------+---------+----------------+\n",
      "|    core|147867716|Datta, Anwitaman|\n",
      "|    core|147867716|  Zhang, Jingchi|\n",
      "+--------+---------+----------------+\n",
      "only showing top 2 rows\n",
      "\n",
      "Total rows: 818070\n",
      "\n",
      "########## journal ##########\n",
      "root\n",
      " |-- api_name: string (nullable = true)\n",
      " |-- api_id: string (nullable = true)\n",
      " |-- issn: string (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      "\n",
      "+--------+---------+---------+--------------------+\n",
      "|api_name|   api_id|     issn|                name|\n",
      "+--------+---------+---------+--------------------+\n",
      "|    core|147815963|0262-4087|                 NaN|\n",
      "|    core|147683048|0022-3263|The Journal of Or...|\n",
      "+--------+---------+---------+--------------------+\n",
      "only showing top 2 rows\n",
      "\n",
      "Total rows: 36550\n",
      "\n",
      "########## keyword ##########\n",
      "root\n",
      " |-- week_start_date: date (nullable = true)\n",
      " |-- n: integer (nullable = true)\n",
      " |-- word: string (nullable = true)\n",
      " |-- count: integer (nullable = true)\n",
      " |-- week_percentage: float (nullable = true)\n",
      "\n",
      "+---------------+---+--------+-----+---------------+\n",
      "|week_start_date|  n|    word|count|week_percentage|\n",
      "+---------------+---+--------+-----+---------------+\n",
      "|     2023-10-02|  1|   study|  358|        0.58796|\n",
      "|     2023-10-02|  1|analysis|  341|        0.56004|\n",
      "+---------------+---+--------+-----+---------------+\n",
      "only showing top 2 rows\n",
      "\n",
      "Total rows: 6017\n"
     ]
    }
   ],
   "source": [
    "schema = 'papers'\n",
    "tables = ['paper', 'author', 'journal', 'keyword']\n",
    "\n",
    "for table in tables:\n",
    "    table_name = f'{schema}.{table}'\n",
    "    df = spark.read.jdbc(url, table_name, properties=properties)\n",
    "    df.createOrReplaceTempView(table)\n",
    "    print(f\"\\n########## {table} ##########\")\n",
    "    df.printSchema()\n",
    "    df.show(2)\n",
    "    print(f\"Total rows: {df.count()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "15080a6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.date(2023, 11, 6)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dates = spark.sql(\"SELECT DISTINCT week_start_date FROM keyword ORDER BY week_start_date DESC\")\n",
    "dates = dates.rdd.map(lambda row: row[0]).collect()\n",
    "current_week = dates[0]\n",
    "current_week"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f4efa14",
   "metadata": {},
   "source": [
    "## Visualize Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "22899165",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "487fadeb2a6b4732baf63d54a623b3b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='table', options=('paper', 'author', 'journal', 'keyword'), value='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@interact\n",
    "def display_tables(table=tables, nrows=(1, 20, 1)):\n",
    "    df = spark.sql(f\"SELECT * FROM {table};\").toPandas()\n",
    "    return df.head(nrows)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c4036da",
   "metadata": {},
   "source": [
    "## Top n-grams By Date Interval "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43501437",
   "metadata": {},
   "source": [
    "### Barplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "517f5c49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2fffceeec2048d097fe8f7efe7fe6b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='start_date', options=(datetime.date(2023, 11, 6), datetime.date(20…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@interact\n",
    "def int_barplot_grams(start_date=dates, n=(1,3,1), limit=(5,20,1)):\n",
    "    query = \"\"\"\n",
    "                SELECT word, count\n",
    "                FROM keyword\n",
    "                WHERE week_start_date = '{week_start}'\n",
    "                AND n = {n}\n",
    "                ORDER BY count DESC\n",
    "                LIMIT {limit}\n",
    "            \"\"\".format(**{'week_start': start_date, 'n': n, 'limit': limit})\n",
    "    viz_functions.barplot_ngrams(spark, query, x='word', y='count')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e267aafb",
   "metadata": {},
   "source": [
    "### Word Cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9931414c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a0e5a9fd8fc4c09913653ec6567ba20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='start_date', options=(datetime.date(2023, 11, 6), datetime.date(20…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "colormaps = [\"gist_heat_r\", \"Reds_r\", \"Purples_r\", \"RdGy_r\", \"RdBu_r\", \"CMRmap_r\"]\n",
    "\n",
    "@interact\n",
    "def it_wordcloud_ngrams(start_date=dates, end_date=dates, n=(1,3,1), limit=(5,20,1), colormap=colormaps):\n",
    "    query = \"\"\"\n",
    "                SELECT word, count\n",
    "                FROM keyword\n",
    "                WHERE week_start_date = '{week_start}'\n",
    "                AND n = {n}\n",
    "                ORDER BY count DESC\n",
    "                LIMIT {limit}\n",
    "            \"\"\".format(**{'week_start': start_date, 'n': n, 'limit': limit})\n",
    "    viz_functions.wordcloud_ngrams(spark, query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a0dbc35",
   "metadata": {},
   "source": [
    "## Keyword Evolution Through Time "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9fe1924f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2849398eab14dd48763dcab81e83ff2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='week', options=(datetime.date(2023, 11, 6), datetime.date(2023, 10…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@interact\n",
    "def it_lineplot_ngrams(week=dates, n=(1,3,1), limit=(4,20,1)):\n",
    "    query = \"\"\"\n",
    "            SELECT kw.week_start_date, kw.word, kw.week_percentage\n",
    "            FROM keyword as kw \n",
    "            INNER JOIN\n",
    "            (\n",
    "                SELECT word, count\n",
    "                FROM keyword\n",
    "                WHERE week_start_date = '{week_start}'\n",
    "                AND n = {n}\n",
    "                ORDER BY count DESC\n",
    "                LIMIT {limit} ) as temp \n",
    "            ON kw.word = temp.word;\n",
    "        \"\"\".format(**{'week_start': week, 'n': n, 'limit': limit})\n",
    "\n",
    "    viz_functions.lineplot_ngrams(spark, query, x=\"week_start_date\", y=\"week_percentage\", hue=\"word\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96b3f367",
   "metadata": {},
   "source": [
    "## Publications per Journal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "36e887ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0aef53bc269343fc96ce466f06b9ac05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='year', options=(2023,), value=2023), IntSlider(value=6, descriptio…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "years = spark.sql(\n",
    "    \"\"\"\n",
    "    SELECT DISTINCT EXTRACT(YEAR FROM published_date) as year\n",
    "    FROM paper \n",
    "    ORDER BY year DESC\n",
    "    \"\"\")\n",
    "years = years.rdd.map(lambda row: row[0]).collect()\n",
    "\n",
    "@interact\n",
    "def it_barplot_journals(year=years, month=(1,12,1), limit=(5,20,1)):\n",
    "    query = \"\"\"\n",
    "                SELECT j.name as Name, j.issn as ISSN, COUNT(*) as count\n",
    "                FROM journal as j\n",
    "                INNER JOIN (\n",
    "                    SELECT api_name, api_id\n",
    "                    FROM paper\n",
    "                    WHERE EXTRACT(MONTH FROM published_date) = {month}\n",
    "                    AND EXTRACT(YEAR FROM published_date) = {year}\n",
    "                ) as p\n",
    "                ON (j.api_name, j.api_id) = (p.api_name, p.api_id)\n",
    "                WHERE j.name IS NOT NULL\n",
    "                AND j.name != 'NaN'\n",
    "                GROUP BY j.name, j.issn\n",
    "                ORDER BY count DESC\n",
    "                LIMIT {limit};\n",
    "            \"\"\".format(**{'month': month, 'year': year, 'limit': limit})\n",
    "    viz_functions.barplot_journals(spark, query, x='Name', y='count')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "428a80aa",
   "metadata": {},
   "source": [
    "## Publications per Author"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45a04597",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b05f42d090f64474a5c0389f82e1c13d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='year', options=(2023,), value=2023), IntSlider(value=6, descriptio…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@interact\n",
    "def barplot_ngrams(year=years, month=(1,12,1), limit=(5,20,1)):\n",
    "    query = \"\"\"\n",
    "                SELECT a.name as Name, COUNT(*) as count\n",
    "                FROM author as a\n",
    "                INNER JOIN (\n",
    "                    SELECT api_name, api_id\n",
    "                    FROM paper\n",
    "                    WHERE EXTRACT(MONTH FROM published_date) = {month}\n",
    "                    AND EXTRACT(YEAR FROM published_date) = {year}\n",
    "                ) as p\n",
    "                ON (a.api_name, a.api_id) = (p.api_name, p.api_id)\n",
    "                WHERE a.name IS NOT NULL\n",
    "                AND a.name != 'NaN'\n",
    "                GROUP BY a.name\n",
    "                ORDER BY count DESC\n",
    "                LIMIT {limit};\n",
    "            \"\"\".format(**{'month': month, 'year': year, 'limit': limit})\n",
    "    viz_functions.barplot_authors(spark, query, x='Name', y='count')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
